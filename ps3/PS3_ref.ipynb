{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import edf\n",
    "from time import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load('../c10_data/train.npz')\n",
    "t_imgs = np.float32(data['imgs'])/255.\n",
    "\n",
    "# Reshape the train image data to (idx, h, w, channel)\n",
    "t_imgs = t_imgs.reshape(50000, 32, 32, 3)\n",
    "t_labels = np.float32(data['labels'])\n",
    "\n",
    "data = np.load('../c10_data/test.npz')\n",
    "v_imgs = np.float32(data['imgs'])/255.\n",
    "\n",
    "# Reshape the valid image data to (idx, h, w, channel)\n",
    "v_imgs = v_imgs.reshape(10000, 32, 32, 3)\n",
    "v_labels = np.float32(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "########################################### Convolution layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ############## \n",
    "class ConvNaive:\n",
    "\n",
    "    def __init__(self,f,k,stride=1,pad=0):\n",
    "        edf.components.append(self)\n",
    "        self.f = f\n",
    "        self.k = k\n",
    "        pad = np.array(pad)\n",
    "        if pad.shape == ():\n",
    "            self.xpad = self.ypad = pad\n",
    "        else:\n",
    "            self.ypad = pad[0]\n",
    "            self.xpad = pad[1]\n",
    "            \n",
    "        self.stride=stride\n",
    "        self.grad = None if f.grad is None and k.grad is None else edf.DT(0) \n",
    "\n",
    "    ####################### Please implement this function####################### \n",
    "    def forward(self):\n",
    "\n",
    "        fshape = self.f.value.shape\n",
    "        kshape = self.k.value.shape \n",
    "                      \n",
    "        b = fshape[0]\n",
    "        h = fshape[1]\n",
    "        w = fshape[2]\n",
    "        c1 = fshape[3] \n",
    "        k = kshape[0]\n",
    "        ch = kshape[3]\n",
    "        \n",
    "        self.value = np.zeros((b,np.int32((h-k+2*self.ypad)/self.stride+1), np.int32((w-k+2*self.xpad)/self.stride+1), ch))\n",
    "        self.padf = np.zeros((b, h+2*self.ypad, w+2*self.xpad, c1))\n",
    "        self.padf[:,self.ypad:h+self.ypad,self.xpad:w+self.xpad, :] = self.f.value\n",
    "        \n",
    "        # over positions in image \n",
    "        for y in range(np.int32((h-k+2*self.ypad)/self.stride + 1)):\n",
    "            for x in range(np.int32((w-k+2*self.xpad)/self.stride + 1)):\n",
    "                inx = self.padf[:,y*self.stride:y*self.stride+k,x*self.stride:x*self.stride+k,:].reshape((b, k*k*c1))\n",
    "                ke = self.k.value.reshape((k*k*c1, ch))\n",
    "                self.value[:,y,x,:] = np.matmul(inx, ke).reshape((b,ch))\n",
    "                \n",
    "    ####################### Please implement this function#######################         \n",
    "    def backward(self):\n",
    "\n",
    "        fshape = self.f.value.shape\n",
    "        kshape = self.k.value.shape\n",
    "\n",
    "        b = fshape[0]\n",
    "        c1 = fshape[3]\n",
    "        k = kshape[0]\n",
    "        ch = kshape[3]\n",
    "\n",
    "        h_hat = self.grad.shape[1]\n",
    "        w_hat = self.grad.shape[2]\n",
    "        h = (h_hat-1)*self.stride + k # padded image\n",
    "        w = (w_hat-1)*self.stride + k # padded image\n",
    "        fil_mid = k//2\n",
    "                \n",
    "        if self.f.grad is not None and self.k.grad is not None:\n",
    "            fgrad = np.zeros((b, h, w, c1))\n",
    "            kgrad = np.zeros((k, k, c1, ch))\n",
    "            k_flip = np.transpose(self.k.value, (0,1,3,2))\t\n",
    "            padf_flip = np.transpose(self.padf, (1,2,3,0))\n",
    "\n",
    "            for y in range(h_hat):\n",
    "                for x in range(w_hat):\n",
    "                    out_grad_value = self.grad[:, y, x, :].reshape(b, ch)\n",
    "                    y_img = y*self.stride; x_img = x*self.stride\n",
    "                    fgrad[:, y_img:y_img+k, x_img:x_img+k, :] += np.dot(out_grad_value, k_flip).reshape(b,k,k,c1)\n",
    "                    kgrad += np.dot(padf_flip[y_img:y_img+k, x_img:x_img+k,:,:], out_grad_value)\n",
    "            \n",
    "            self.f.grad = self.f.grad + fgrad[:, self.ypad:h-self.ypad,self.xpad:w-self.xpad, :]\n",
    "            self.k.grad = self.k.grad + kgrad\n",
    "\n",
    "########################################### MaxPool layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ##############             \n",
    "class MaxPool:\n",
    "    def __init__(self,x,ksz=2,stride=None):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.ksz=ksz\n",
    "        if stride is None:\n",
    "            self.stride=ksz\n",
    "        else:\n",
    "            self.stride=stride\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "\n",
    "    ####################### Please implement this function#######################     \n",
    "    def forward(self):\n",
    "        st = self.stride\n",
    "        ksz = self.ksz\n",
    "        self.value = -np.inf\n",
    "        for y in range(ksz):\n",
    "            for x in range(ksz):\n",
    "                self.value = np.maximum(self.value, self.x.value[:,y::st,x::st,:])\n",
    "\n",
    "    ####################### Please implement this function#######################             \n",
    "    def backward(self):\n",
    "        if self.x.grad is not None:\n",
    "            st = self.stride\n",
    "            ksz = self.ksz\n",
    "            self.x.grad = self.x.grad + np.zeros_like(self.x.value)\n",
    "            for y in range(ksz):\n",
    "                for x in range(ksz):\n",
    "                    self.x.grad[:,y::st,x::st,:] = self.grad * \\\n",
    "                            (self.value == self.x.value[:,y::st,x::st,:]) + \\\n",
    "                            self.x.grad[:,y::st,x::st,:]\n",
    "\n",
    "                            \n",
    "########################################### AvePool layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ##############                             \n",
    "class AvePool:\n",
    "    def __init__(self,x,ksz=2,stride=None):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.ksz=ksz\n",
    "        if stride is None:\n",
    "            self.stride=ksz\n",
    "        else:\n",
    "            self.stride=stride\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "        \n",
    "    ####################### Please implement this function#######################   \n",
    "    def forward(self):\n",
    "        st = self.stride\n",
    "        ksz = self.ksz\n",
    "        self.value = edf.DT(0)\n",
    "        for y in range(ksz):\n",
    "            for x in range(ksz):\n",
    "                self.value += self.x.value[:,y::st,x::st,:]\n",
    "        self.value = self.value/ksz/ksz\n",
    "\n",
    "    ####################### Please implement this function#######################    \n",
    "    def backward(self):\n",
    "        if self.x.grad is not None:\n",
    "            st = self.stride\n",
    "            ksz = self.ksz\n",
    "            self.x.grad = self.x.grad + np.zeros_like(self.x.value)\n",
    "            for y in range(ksz):\n",
    "                for x in range(ksz):\n",
    "                    self.x.grad[:,y::st,x::st,:] = self.grad/ksz/ksz + \\\n",
    "                            self.x.grad[:,y::st,x::st,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility function for shape inference with broadcasting\n",
    "def bcast(x,y):\n",
    "    xs = np.array(x.shape)\n",
    "    ys = np.array(y.shape)\n",
    "    pad = len(xs)-len(ys)\n",
    "    if pad > 0:\n",
    "        ys = np.pad(ys,[[pad,0]],'constant')\n",
    "    elif pad < 0:\n",
    "        xs = np.pad(xs,[[-pad,0]],'constant')\n",
    "    os = np.maximum(xs,ys)\n",
    "    xred = tuple([idx for idx in np.where(xs < os)][0])\n",
    "    yred = tuple([idx for idx in np.where(ys < os)][0])\n",
    "    return xred,yred\n",
    "\n",
    "'''\n",
    "  function name: _im2c\n",
    "  function usage: Reshape the tensor value to specific shape fidx and pick the valid pixel.\n",
    "'''\n",
    "def _im2c(value,fidx,vld):\n",
    "    if vld is not None:\n",
    "        fmat = np.zeros(np.prod(fidx.shape),dtype=edf.DT)\n",
    "        fmat[vld] = value.reshape([-1])[fidx.reshape([-1])[vld]]\n",
    "    else:\n",
    "        fmat = value.reshape([-1])[fidx.reshape([-1])]\n",
    "    fmat = fmat.reshape(fidx.shape)\n",
    "    return fmat\n",
    "\n",
    "\n",
    "'''\n",
    "  Class name: Conv\n",
    "  Class usage: convolution layer given image feature f and filter k, stride and pad. this is use the image to column trick and fast. \n",
    "  Class function:\n",
    "      forward: do concolution\n",
    "      backward: calculate derivative w.r.t to f and filter k\n",
    "      \n",
    "'''\n",
    "class Conv:\n",
    "    \n",
    "    def __init__(self,f,k,stride=1,pad=0):\n",
    "        edf.components.append(self)\n",
    "        self.f = f\n",
    "        self.k = k\n",
    "        pad = np.array(pad)\n",
    "        if pad.shape == ():\n",
    "            self.xpad = self.ypad = pad\n",
    "        else:\n",
    "            self.ypad = pad[0]\n",
    "            self.xpad = pad[1]\n",
    "        self.stride=stride\n",
    "        self.grad = None if f.grad is None and k.grad is None else edf.DT(0)\n",
    "\n",
    "        self.fshape = None\n",
    "        self.kshape = None\n",
    "\n",
    "\n",
    "    def im2c_setup(self,fshape,kshape):\n",
    "        self.fshape = fshape\n",
    "        self.kshape = kshape\n",
    "\n",
    "        # For forward pass\n",
    "        y,x = np.meshgrid(\n",
    "            range(-self.ypad,fshape[1]+self.ypad-kshape[0]+1,self.stride),\n",
    "            range(-self.xpad,fshape[2]+self.xpad-kshape[1]+1,self.stride),\n",
    "            indexing='ij')\n",
    "        oshape = (fshape[0],)+y.shape+(kshape[-1],)\n",
    "        yd,xd = np.meshgrid(range(kshape[0]),range(kshape[1]),indexing='ij')\n",
    "        y = y.reshape([-1,1,1])+yd.reshape([-1,1])\n",
    "        x = x.reshape([-1,1,1])+xd.reshape([-1,1])\n",
    "        fidx = np.reshape(range(fshape[0]),[-1,1,1,1])*fshape[1]\n",
    "        fidx = ((fidx + y)*fshape[2] + x)*fshape[3] + range(fshape[3])\n",
    "        fidx = fidx.reshape([fidx.shape[0]*fidx.shape[1],-1])\n",
    "        vld = ((y >= 0) * (y < fshape[1]) * (x >= 0) * (x < fshape[2]))\n",
    "        if not np.all(vld):\n",
    "            vld = np.tile(vld[...,np.newaxis],[fshape[0],1,1,fshape[-1]]).reshape(-1)\n",
    "        else:\n",
    "            vld = None\n",
    "        self.fidx = fidx\n",
    "        self.vld = vld\n",
    "        self.oshape = oshape\n",
    "\n",
    "        # For backward pass\n",
    "        if self.f.grad is None:\n",
    "            return\n",
    "\n",
    "        y,x = np.meshgrid(range(fshape[1]),range(fshape[2]),indexing='ij')\n",
    "        yd,xd = np.meshgrid(range(kshape[0]),range(kshape[1]),indexing='ij')\n",
    "        y = y.reshape([-1,1,1])-yd.reshape([-1,1])+self.ypad\n",
    "        x = x.reshape([-1,1,1])-xd.reshape([-1,1])+self.xpad\n",
    "        bfidx = np.reshape(range(fshape[0]),[-1,1,1,1])*oshape[1]\n",
    "        bfidx = ((bfidx + y)*oshape[2] + x)*oshape[3] + range(oshape[3])\n",
    "        bfidx = bfidx.reshape([bfidx.shape[0]*bfidx.shape[1],-1])\n",
    "        bvld = ((y >= 0) * (y < oshape[1]) * (x >= 0) * (x < oshape[2]))\n",
    "        if not np.all(bvld):\n",
    "            bvld = np.tile(bvld[...,np.newaxis],[oshape[0],1,1,oshape[-1]]).reshape(-1)\n",
    "        else:\n",
    "            bvld = None\n",
    "        self.bfidx = bfidx\n",
    "        self.bvld = bvld\n",
    "\n",
    "    def forward(self):\n",
    "        fshape = self.f.value.shape\n",
    "        kshape = self.k.value.shape\n",
    "        if fshape != self.fshape or kshape != self.kshape:\n",
    "            self.im2c_setup(fshape,kshape)\n",
    "\n",
    "        fmat = _im2c(self.f.value,self.fidx,self.vld)\n",
    "        kmat = self.k.value.reshape([-1,kshape[-1]])\n",
    "        if self.k.grad is not None:\n",
    "            self.fmat = fmat\n",
    "        self.value = np.matmul(fmat,kmat).reshape(self.oshape)\n",
    "\n",
    "    def backward(self):\n",
    "        if self.f.grad is not None:\n",
    "            gmat = _im2c(self.grad,self.bfidx,self.bvld)\n",
    "            kmat = np.transpose(self.k.value,[0,1,3,2]).copy().reshape([-1,self.kshape[-2]])\n",
    "            self.f.grad = self.f.grad + np.matmul(gmat,kmat).reshape(self.fshape)\n",
    "\n",
    "        if self.k.grad is not None:\n",
    "            kgrad = np.matmul(self.fmat.T,self.grad.reshape([-1,self.kshape[-1]]))\n",
    "            self.k.grad = self.k.grad + kgrad.reshape(self.kshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for repeatability\n",
    "np.random.seed(0)\n",
    "\n",
    "# Inputs and parameters\n",
    "inp = edf.Value()\n",
    "lab = edf.Value()\n",
    "\n",
    "########################## Simple Convolution Nerual Network Model for Cifar 10 ##################################\n",
    "################################################ Please implement the model ######################################\n",
    "\n",
    "prev_channel = 3\n",
    "pred = inp\n",
    "\n",
    "# the convolution and pooling layer\n",
    "W = edf.Param(edf.xavier((3, 3, prev_channel, 32)))\n",
    "B = edf.Param(np.zeros((32)))\n",
    "pred = edf.RELU(edf.Add(Conv(pred,W,1,1),B)) # 32+2-3+1=32   \n",
    "pred = MaxPool(pred, 4) # 8*8\n",
    "W = edf.Param(edf.xavier((3,3, 32, 64)))\n",
    "B = edf.Param(np.zeros((64)))\n",
    "pred = edf.RELU(edf.Add(Conv(pred,W,1,0), B)) # (8-3)/1+1 = 6    \n",
    "pred = AvePool(pred, 6) # 1*1*64\n",
    "\n",
    "W = edf.Param(edf.xavier((1, 1, 64, 10)))\n",
    "B = edf.Param(np.zeros((10)))\n",
    "pred = edf.RELU(edf.Add(Conv(pred,W,1,0),B)) # 1-1+1=1\n",
    "pred = edf.Reshape(pred,[-1, 10])\n",
    "\n",
    "# the classification layer\n",
    "pred = edf.SoftMax(pred)\n",
    "loss = edf.Mean(edf.LogLoss(edf.Aref(pred,lab)))\n",
    "acc = edf.Accuracy(pred,lab)\n",
    "\n",
    "\n",
    "\n",
    "# evaluation bucket\n",
    "bucket = 100\n",
    "def eval_train():    \n",
    "    \n",
    "    # we only choose 1/5 of the train images for evaluation since evaluation the whole images is time consuming\n",
    "    eval_imgs = t_imgs[::5]\n",
    "    eval_labels = t_labels[::5]\n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for seq in range(bucket):\n",
    "        inp.set(eval_imgs[seq::bucket])\n",
    "        lab.set(eval_labels[seq::bucket])\n",
    "        edf.Forward()\n",
    "        avg_acc += acc.value\n",
    "        avg_loss += loss.value\n",
    "    \n",
    "    return avg_acc/bucket, avg_loss/bucket\n",
    "        \n",
    "def eval_test():\n",
    "    \n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    for seq in range(bucket):\n",
    "        inp.set(v_imgs[seq::bucket])\n",
    "        lab.set(v_labels[seq::bucket])\n",
    "        edf.Forward()\n",
    "        avg_acc += acc.value\n",
    "        avg_loss += loss.value\n",
    "    \n",
    "    return avg_acc/bucket, avg_loss/bucket\n",
    "\n",
    "# initial accuracy \n",
    "random_acc, random_loss = eval_test()\n",
    "print(\"Random test loss = %.4f, accuracy = %.4f\" % (random_loss, random_acc))\n",
    "\n",
    "\n",
    "################################################# train loop ######################################################\n",
    "ep = 0\n",
    "epoch = 10\n",
    "batch = 100\n",
    "train_loss = []; train_acc = []; test_loss =[]; test_acc = []\n",
    "stime = time()\n",
    "batches = range(0, len(t_labels), batch)\n",
    "\n",
    "while ep < epoch:\n",
    "\n",
    "    # randon shuffle the train data in each epoch\n",
    "    perm = np.random.permutation(len(t_labels))\n",
    "\n",
    "    for k in batches:\n",
    "        inp.set(t_imgs[perm[k:k+batch]])\n",
    "        lab.set(t_labels[perm[k:k+batch]])\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.Adam()\n",
    "        \n",
    "    # evaluate on trainset\n",
    "    t_acc, t_loss = eval_train()\n",
    "    print(\"Epoch %d: train loss = %.4f [%.3f secs]\" % (ep, t_loss,time()-stime))\n",
    "    train_loss.append(t_loss)\n",
    "    train_acc.append(t_acc)\n",
    "\n",
    "    # evaluate on testset\n",
    "    v_acc, v_loss = eval_test()\n",
    "    print(\"test accuracy = %.4f\" % v_acc)\n",
    "    test_loss.append(v_loss)\n",
    "    test_acc.append(v_acc)\n",
    "    stime = time()\n",
    "    ep += 1      \n",
    "\n",
    "\n",
    "# plot\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, color='red')\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, color='blue')\n",
    "plt.legend(['test loss', 'train loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(np.arange(len(test_acc)), test_acc, color='red')\n",
    "plt.plot(np.arange(len(train_acc)), train_acc, color='blue')\n",
    "plt.legend(['test acc', 'train acc'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
