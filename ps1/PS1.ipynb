{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import edf\n",
    "from time import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindata = './mnist_data/train.npz'\n",
    "valdata = './mnist_data/test.npz'\n",
    "\n",
    "data = np.load(traindata)\n",
    "t_imgs = np.float32(data['imgs'])/255.\n",
    "t_labels = np.float32(data['labels'])\n",
    "\n",
    "data = np.load(valdata)\n",
    "v_imgs = np.float32(data['imgs'])/255.\n",
    "v_labels = np.float32(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################################we use sigmoid to demonstrate the edf works###################################\n",
    "# for repeatability\n",
    "np.random.seed(0)\n",
    "# Inputs and parameters\n",
    "inp = edf.Value()\n",
    "lab = edf.Value()\n",
    "\n",
    "W1 = edf.Param(edf.xavier((28*28,128)))\n",
    "B1 = edf.Param(np.zeros((128)))\n",
    "W2 = edf.Param(edf.xavier((128,10)))\n",
    "B2 = edf.Param(np.zeros((10)))\n",
    "\n",
    "########### Model #############\n",
    "A1 = edf.Add(edf.VDot(inp,W1),B1)\n",
    "hidden = edf.Sigmoid(A1)\n",
    "A2 = edf.Add(edf.VDot(hidden,W2),B2)\n",
    "pred = edf.SoftMax(A2)\n",
    "log = edf.Log(edf.Aref(pred,lab))\n",
    "loss = edf.Mul(log,edf.Value(-1))\n",
    "acc = edf.Accuracy(pred,lab)\n",
    "\n",
    "\n",
    "# evaluation function\n",
    "def eval(v_imgs, v_labels):\n",
    "    accuracy = 0.\n",
    "    objective = 0.\n",
    "    for k in range(len(v_labels)):    \n",
    "        inp.set(v_imgs[k])\n",
    "        lab.set(v_labels[k])\n",
    "        edf.Forward()\n",
    "        accuracy += acc.value\n",
    "        objective += loss.value\n",
    "        \n",
    "    accuracy /= len(v_labels)\n",
    "    objective /= len(v_labels)\n",
    "    return accuracy, objective\n",
    "\n",
    "accuracy,objective = eval(v_imgs, v_labels)\n",
    "print(\"Random accuracy = %.4f\" % accuracy)\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "ep = 0\n",
    "stime = time()\n",
    "lr = 0.01\n",
    "epoch = 10\n",
    "\n",
    "while ep < epoch:\n",
    "\n",
    "    # randon shuffle the train data in each epoch\n",
    "    perm = np.random.permutation(len(t_labels))\n",
    "    for k in range(len(t_labels)):    \n",
    "        inp.set(t_imgs[perm[k]])\n",
    "        lab.set(t_labels[perm[k]])\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.SGD(lr)\n",
    "\n",
    "    # evaluate on train set\n",
    "    avg_acc, avg_loss = eval(t_imgs, t_labels)\n",
    "    print(\"Epoch %d: train loss = %.4f [%.3f secs]\" % (ep, avg_loss,time()-stime))\n",
    "    train_loss.append(avg_loss)\n",
    "    train_acc.append(avg_acc)\n",
    "\n",
    "    # evaluate on testset\n",
    "    avg_acc, avg_loss = eval(v_imgs, v_labels)\n",
    "    print(\"test accuracy=%.4f\" % avg_acc)\n",
    "    test_loss.append(avg_acc)\n",
    "    test_acc.append(avg_loss)\n",
    "    stime = time()\n",
    "    ep += 1\n",
    "\n",
    "# plot\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, color='red')\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, color='blue')\n",
    "plt.legend(['test loss', 'train loss'], loc='upper right')\n",
    "plt.show\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(np.arange(len(test_acc)), test_acc, color='red')\n",
    "plt.plot(np.arange(len(train_acc)), train_acc, color='blue')\n",
    "plt.legend(['test acc', 'train acc'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# please complete the forward and backward function in Tanh class and test it.\n",
    "class Tanh:\n",
    "    \n",
    "    def __init__(self,x):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        \n",
    "    def backward(self):\n",
    "        \n",
    "        \n",
    "\n",
    "# for repeatability\n",
    "np.random.seed(0)\n",
    "# Inputs and parameters\n",
    "inp = edf.Value()\n",
    "lab = edf.Value()\n",
    "\n",
    "W1 = edf.Param(edf.xavier((28*28,128)))\n",
    "B1 = edf.Param(np.zeros((128)))\n",
    "W2 = edf.Param(edf.xavier((128,10)))\n",
    "B2 = edf.Param(np.zeros((10)))\n",
    "\n",
    "########### Model #############\n",
    "# Here we change sigmoid to Tanh\n",
    "A1 = edf.Add(edf.VDot(inp,W1),B1)\n",
    "hidden = Tanh(A1)\n",
    "A2 = edf.Add(edf.VDot(hidden,W2),B2)\n",
    "pred = edf.SoftMax(A2)\n",
    "log = edf.Log(edf.Aref(pred,lab))\n",
    "loss = edf.Mul(log,edf.Value(-1))\n",
    "acc = edf.Accuracy(pred,lab)\n",
    "\n",
    "\n",
    "# evaluation function\n",
    "def eval(v_imgs, v_labels):\n",
    "    accuracy = 0.\n",
    "    objective = 0.\n",
    "    for k in range(len(v_labels)):    \n",
    "        inp.set(v_imgs[k])\n",
    "        lab.set(v_labels[k])\n",
    "        edf.Forward()\n",
    "        accuracy += acc.value\n",
    "        objective += loss.value\n",
    "        \n",
    "    accuracy /= len(v_labels)\n",
    "    objective /= len(v_labels)\n",
    "    return accuracy, objective\n",
    "\n",
    "accuracy,objective = eval(v_imgs, v_labels)\n",
    "print(\"Random accuracy = %.4f\" % accuracy)\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "ep = 0\n",
    "stime = time()\n",
    "lr = 0.01\n",
    "epoch = 10\n",
    "\n",
    "while ep < epoch:\n",
    "\n",
    "    # randon shuffle the train data in each epoch\n",
    "    perm = np.random.permutation(len(t_labels))\n",
    "    for k in range(len(t_labels)):    \n",
    "        inp.set(t_imgs[perm[k]])\n",
    "        lab.set(t_labels[perm[k]])\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.SGD(lr)\n",
    "\n",
    "    # evaluate on train set\n",
    "    avg_acc, avg_loss = eval(t_imgs, t_labels)\n",
    "    print(\"Epoch %d: train loss = %.4f [%.3f secs]\" % (ep, avg_loss,time()-stime))\n",
    "    train_loss.append(avg_loss)\n",
    "    train_acc.append(avg_acc)\n",
    "\n",
    "    # evaluate on testset\n",
    "    avg_acc, avg_loss = eval(v_imgs, v_labels)\n",
    "    print(\"test accuracy=%.4f\" % avg_acc)\n",
    "    test_loss.append(avg_acc)\n",
    "    test_acc.append(avg_loss)\n",
    "    stime = time()\n",
    "    ep += 1\n",
    "\n",
    "# after training, you should be able to get around 97% test accuracy and training loss under 0.1 on mnist data.\n",
    "# plot\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, color='red')\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, color='blue')\n",
    "plt.legend(['test loss', 'train loss'], loc='upper right')\n",
    "plt.show\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(np.arange(len(test_acc)), test_acc, color='red')\n",
    "plt.plot(np.arange(len(train_acc)), train_acc, color='blue')\n",
    "plt.legend(['test acc', 'train acc'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# please complete the forward and backward function in Relu class and test it.\n",
    "class Relu:\n",
    "\n",
    "    def __init__(self,x):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        \n",
    "    def backward(self):\n",
    "        \n",
    "        \n",
    "# for repeatability\n",
    "np.random.seed(0)\n",
    "# Inputs and parameters\n",
    "inp = edf.Value()\n",
    "lab = edf.Value()\n",
    "\n",
    "W1 = edf.Param(edf.xavier((28*28,128)))\n",
    "B1 = edf.Param(np.zeros((128)))\n",
    "W2 = edf.Param(edf.xavier((128,10)))\n",
    "B2 = edf.Param(np.zeros((10)))\n",
    "\n",
    "########### Model #############\n",
    "# Here we change sigmoid to relu\n",
    "A1 = edf.Add(edf.VDot(inp,W1),B1)\n",
    "hidden = Relu(A1)\n",
    "A2 = edf.Add(edf.VDot(hidden,W2),B2)\n",
    "pred = edf.SoftMax(A2)\n",
    "log = edf.Log(edf.Aref(pred,lab))\n",
    "loss = edf.Mul(log,edf.Value(-1))\n",
    "acc = edf.Accuracy(pred,lab)\n",
    "\n",
    "# evaluation function\n",
    "def eval(v_imgs, v_labels):\n",
    "    accuracy = 0.\n",
    "    objective = 0.\n",
    "    for k in range(len(v_labels)):    \n",
    "        inp.set(v_imgs[k])\n",
    "        lab.set(v_labels[k])\n",
    "        edf.Forward()\n",
    "        accuracy += acc.value\n",
    "        objective += loss.value\n",
    "        \n",
    "    accuracy /= len(v_labels)\n",
    "    objective /= len(v_labels)\n",
    "    return accuracy, objective\n",
    "\n",
    "accuracy,objective = eval(v_imgs, v_labels)\n",
    "print(\"Random accuracy = %.4f\" % accuracy)\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "ep = 0\n",
    "stime = time()\n",
    "lr = 0.01\n",
    "epoch = 10\n",
    "\n",
    "while ep < epoch:\n",
    "\n",
    "    # randon shuffle the train data in each epoch\n",
    "    perm = np.random.permutation(len(t_labels))\n",
    "    for k in range(len(t_labels)):    \n",
    "        inp.set(t_imgs[perm[k]])\n",
    "        lab.set(t_labels[perm[k]])\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.SGD(lr)\n",
    "\n",
    "    # evaluate on train set\n",
    "    avg_acc, avg_loss = eval(t_imgs, t_labels)\n",
    "    print(\"Epoch %d: train loss = %.4f [%.3f secs]\" % (ep, avg_loss,time()-stime))\n",
    "    train_loss.append(avg_loss)\n",
    "    train_acc.append(avg_acc)\n",
    "\n",
    "    # evaluate on testset\n",
    "    avg_acc, avg_loss = eval(v_imgs, v_labels)\n",
    "    print(\"test accuracy=%.4f\" % avg_acc)\n",
    "    test_loss.append(avg_acc)\n",
    "    test_acc.append(avg_loss)\n",
    "    stime = time()\n",
    "    ep += 1\n",
    "\n",
    "# after training, you should be able to get around 97% test accuracy and training loss under 0.1 on mnist data.\n",
    "# plot\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, color='red')\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, color='blue')\n",
    "plt.legend(['test loss', 'train loss'], loc='upper right')\n",
    "plt.show\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(np.arange(len(test_acc)), test_acc, color='red')\n",
    "plt.plot(np.arange(len(train_acc)), train_acc, color='blue')\n",
    "plt.legend(['test acc', 'train acc'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
